### from the metrics below, someimportant ones, which show inference performance:

- vllm:prefix_cache_queries_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0  
- vllm:prompt_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0  
- vllm:generation_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0  
- vllm:iteration_tokens_total_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0  
- vllm:iteration_tokens_total_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 424.0  
- vllm:time_to_first_token_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.05244112014770508





rteixeira@shockwave:~$ curl -s http://localhost:8002/metrics

```
# HELP python_gc_objects_collected_total Objects collected during gc
# TYPE python_gc_objects_collected_total counter
python_gc_objects_collected_total{generation="0"} 13464.0
python_gc_objects_collected_total{generation="1"} 1728.0
python_gc_objects_collected_total{generation="2"} 1405.0
# HELP python_gc_objects_uncollectable_total Uncollectable objects found during GC
# TYPE python_gc_objects_uncollectable_total counter
python_gc_objects_uncollectable_total{generation="0"} 0.0
python_gc_objects_uncollectable_total{generation="1"} 0.0
python_gc_objects_uncollectable_total{generation="2"} 0.0
# HELP python_gc_collections_total Number of times this generation was collected
# TYPE python_gc_collections_total counter
python_gc_collections_total{generation="0"} 1521.0
python_gc_collections_total{generation="1"} 138.0
python_gc_collections_total{generation="2"} 10.0
# HELP python_info Python platform information
# TYPE python_info gauge
python_info{implementation="CPython",major="3",minor="12",patchlevel="12",version="3.12.12"} 1.0
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 3.7811392512e+010
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 1.111552e+09
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.77222427916e+09
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 30.38
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 47.0
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 524288.0
# HELP vllm:num_requests_running Number of requests in model execution batches.
# TYPE vllm:num_requests_running gauge
vllm:num_requests_running{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:num_requests_waiting Number of requests waiting to be processed.
# TYPE vllm:num_requests_waiting gauge
vllm:num_requests_waiting{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:engine_sleep_state Engine sleep state; awake = 0 means engine is sleeping; awake = 1 means engine is awake; weights_offloaded = 1 means sleep level 1; discard_all = 1 means sleep level 2.
# TYPE vllm:engine_sleep_state gauge
vllm:engine_sleep_state{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",sleep_state="awake"} 1.0
vllm:engine_sleep_state{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",sleep_state="weights_offloaded"} 0.0
vllm:engine_sleep_state{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",sleep_state="discard_all"} 0.0
# HELP vllm:kv_cache_usage_perc KV-cache usage. 1 means 100 percent usage.
# TYPE vllm:kv_cache_usage_perc gauge
vllm:kv_cache_usage_perc{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prefix_cache_queries_total Prefix cache queries, in terms of number of queried tokens.
# TYPE vllm:prefix_cache_queries_total counter
vllm:prefix_cache_queries_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:prefix_cache_queries_created Prefix cache queries, in terms of number of queried tokens.
# TYPE vllm:prefix_cache_queries_created gauge
vllm:prefix_cache_queries_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961779263e+09
# HELP vllm:prefix_cache_hits_total Prefix cache hits, in terms of number of cached tokens.
# TYPE vllm:prefix_cache_hits_total counter
vllm:prefix_cache_hits_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prefix_cache_hits_created Prefix cache hits, in terms of number of cached tokens.
# TYPE vllm:prefix_cache_hits_created gauge
vllm:prefix_cache_hits_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961779928e+09
# HELP vllm:external_prefix_cache_queries_total External prefix cache queries from KV connector cross-instance cache sharing, in terms of number of queried tokens.
# TYPE vllm:external_prefix_cache_queries_total counter
vllm:external_prefix_cache_queries_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:external_prefix_cache_queries_created External prefix cache queries from KV connector cross-instance cache sharing, in terms of number of queried tokens.
# TYPE vllm:external_prefix_cache_queries_created gauge
vllm:external_prefix_cache_queries_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961780334e+09
# HELP vllm:external_prefix_cache_hits_total External prefix cache hits from KV connector cross-instance cache sharing, in terms of number of cached tokens.
# TYPE vllm:external_prefix_cache_hits_total counter
vllm:external_prefix_cache_hits_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:external_prefix_cache_hits_created External prefix cache hits from KV connector cross-instance cache sharing, in terms of number of cached tokens.
# TYPE vllm:external_prefix_cache_hits_created gauge
vllm:external_prefix_cache_hits_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961780717e+09
# HELP vllm:mm_cache_queries_total Multi-modal cache queries, in terms of number of queried items.
# TYPE vllm:mm_cache_queries_total counter
vllm:mm_cache_queries_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:mm_cache_queries_created Multi-modal cache queries, in terms of number of queried items.
# TYPE vllm:mm_cache_queries_created gauge
vllm:mm_cache_queries_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961781135e+09
# HELP vllm:mm_cache_hits_total Multi-modal cache hits, in terms of number of cached items.
# TYPE vllm:mm_cache_hits_total counter
vllm:mm_cache_hits_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:mm_cache_hits_created Multi-modal cache hits, in terms of number of cached items.
# TYPE vllm:mm_cache_hits_created gauge
vllm:mm_cache_hits_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961781554e+09
# HELP vllm:num_preemptions_total Cumulative number of preemption from the engine.
# TYPE vllm:num_preemptions_total counter
vllm:num_preemptions_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:num_preemptions_created Cumulative number of preemption from the engine.
# TYPE vllm:num_preemptions_created gauge
vllm:num_preemptions_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961781926e+09
# HELP vllm:prompt_tokens_total Number of prefill tokens processed.
# TYPE vllm:prompt_tokens_total counter
vllm:prompt_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:prompt_tokens_created Number of prefill tokens processed.
# TYPE vllm:prompt_tokens_created gauge
vllm:prompt_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.772224396178228e+09
# HELP vllm:prompt_tokens_by_source_total Number of prompt tokens by source.
# TYPE vllm:prompt_tokens_by_source_total counter
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_compute"} 24.0
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_cache_hit"} 0.0
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="external_kv_transfer"} 0.0
# HELP vllm:prompt_tokens_by_source_created Number of prompt tokens by source.
# TYPE vllm:prompt_tokens_by_source_created gauge
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_compute"} 1.7722243961782753e+09
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_cache_hit"} 1.7722243961782959e+09
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="external_kv_transfer"} 1.7722243961783123e+09
# HELP vllm:prompt_tokens_cached_total Number of cached prompt tokens (local + external).
# TYPE vllm:prompt_tokens_cached_total counter
vllm:prompt_tokens_cached_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prompt_tokens_cached_created Number of cached prompt tokens (local + external).
# TYPE vllm:prompt_tokens_cached_created gauge
vllm:prompt_tokens_cached_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961783535e+09
# HELP vllm:prompt_tokens_recomputed_total Number of cached tokens recomputed for forward pass.
# TYPE vllm:prompt_tokens_recomputed_total counter
vllm:prompt_tokens_recomputed_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prompt_tokens_recomputed_created Number of cached tokens recomputed for forward pass.
# TYPE vllm:prompt_tokens_recomputed_created gauge
vllm:prompt_tokens_recomputed_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961783931e+09
# HELP vllm:generation_tokens_total Number of generation tokens processed.
# TYPE vllm:generation_tokens_total counter
vllm:generation_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:generation_tokens_created Number of generation tokens processed.
# TYPE vllm:generation_tokens_created gauge
vllm:generation_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961784277e+09
# HELP vllm:request_success_total Count of successfully processed requests.
# TYPE vllm:request_success_total counter
vllm:request_success_total{engine="0",finished_reason="stop",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_success_total{engine="0",finished_reason="length",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_success_total{engine="0",finished_reason="abort",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_success_total{engine="0",finished_reason="error",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:request_success_created Count of successfully processed requests.
# TYPE vllm:request_success_created gauge
vllm:request_success_created{engine="0",finished_reason="stop",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961784909e+09
vllm:request_success_created{engine="0",finished_reason="length",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961785147e+09
vllm:request_success_created{engine="0",finished_reason="abort",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961785393e+09
vllm:request_success_created{engine="0",finished_reason="error",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961785564e+09
# HELP vllm:request_prompt_tokens Number of prefill tokens processed.
# TYPE vllm:request_prompt_tokens histogram
vllm:request_prompt_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:request_prompt_tokens_created Number of prefill tokens processed.
# TYPE vllm:request_prompt_tokens_created gauge
vllm:request_prompt_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961786902e+09
# HELP vllm:request_generation_tokens Number of generation tokens processed.
# TYPE vllm:request_generation_tokens histogram
vllm:request_generation_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:request_generation_tokens_created Number of generation tokens processed.
# TYPE vllm:request_generation_tokens_created gauge
vllm:request_generation_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.772224396178866e+09
# HELP vllm:iteration_tokens_total Histogram of number of tokens per engine_step.
# TYPE vllm:iteration_tokens_total histogram
vllm:iteration_tokens_total_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:iteration_tokens_total_bucket{engine="0",le="8.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:iteration_tokens_total_bucket{engine="0",le="16.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:iteration_tokens_total_bucket{engine="0",le="32.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="64.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="128.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="256.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="512.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="1024.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="2048.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="4096.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="8192.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="16384.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 424.0
# HELP vllm:iteration_tokens_total_created Histogram of number of tokens per engine_step.
# TYPE vllm:iteration_tokens_total_created gauge
vllm:iteration_tokens_total_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961789832e+09
# HELP vllm:request_max_num_generation_tokens Histogram of maximum number of requested generation tokens.
# TYPE vllm:request_max_num_generation_tokens histogram
vllm:request_max_num_generation_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:request_max_num_generation_tokens_created Histogram of maximum number of requested generation tokens.
# TYPE vllm:request_max_num_generation_tokens_created gauge
vllm:request_max_num_generation_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.772224396179098e+09
# HELP vllm:request_params_n Histogram of the n request parameter.
# TYPE vllm:request_params_n histogram
vllm:request_params_n_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_n_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
# HELP vllm:request_params_n_created Histogram of the n request parameter.
# TYPE vllm:request_params_n_created gauge
vllm:request_params_n_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961791983e+09
# HELP vllm:request_params_max_tokens Histogram of the max_tokens request parameter.
# TYPE vllm:request_params_max_tokens histogram
vllm:request_params_max_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_params_max_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_max_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_max_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_max_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_max_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_max_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_params_max_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:request_params_max_tokens_created Histogram of the max_tokens request parameter.
# TYPE vllm:request_params_max_tokens_created gauge
vllm:request_params_max_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961792803e+09
# HELP vllm:time_to_first_token_seconds Histogram of time to first token in seconds.
# TYPE vllm:time_to_first_token_seconds histogram
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.001",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.005",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.01",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.02",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.04",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.06",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.08",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.1",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.25",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="0.75",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="7.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="80.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="160.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="640.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="2560.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:time_to_first_token_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.05244112014770508
# HELP vllm:time_to_first_token_seconds_created Histogram of time to first token in seconds.
# TYPE vllm:time_to_first_token_seconds_created gauge
vllm:time_to_first_token_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961797676e+09
# HELP vllm:inter_token_latency_seconds Histogram of inter-token latency in seconds.
# TYPE vllm:inter_token_latency_seconds histogram
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.01",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.025",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.05",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.075",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.1",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.15",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.2",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.4",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="0.75",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="7.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="80.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:inter_token_latency_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 11.669890475997818
# HELP vllm:inter_token_latency_seconds_created Histogram of inter-token latency in seconds.
# TYPE vllm:inter_token_latency_seconds_created gauge
vllm:inter_token_latency_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961799254e+09
# HELP vllm:request_time_per_output_token_seconds Histogram of time_per_output_token_seconds per request.
# TYPE vllm:request_time_per_output_token_seconds histogram
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.01",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.025",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.05",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.075",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.1",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.15",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.2",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.4",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="0.75",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="7.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="80.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_time_per_output_token_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.029247845804505807
# HELP vllm:request_time_per_output_token_seconds_created Histogram of time_per_output_token_seconds per request.
# TYPE vllm:request_time_per_output_token_seconds_created gauge
vllm:request_time_per_output_token_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961800573e+09
# HELP vllm:e2e_request_latency_seconds Histogram of e2e request latency in seconds.
# TYPE vllm:e2e_request_latency_seconds histogram
vllm:e2e_request_latency_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="0.8",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="1.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="15.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="30.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="60.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="120.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="240.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="480.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="960.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="1920.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="7680.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:e2e_request_latency_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 11.722157955169678
# HELP vllm:e2e_request_latency_seconds_created Histogram of e2e request latency in seconds.
# TYPE vllm:e2e_request_latency_seconds_created gauge
vllm:e2e_request_latency_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961801722e+09
# HELP vllm:request_queue_time_seconds Histogram of time spent in WAITING phase for request.
# TYPE vllm:request_queue_time_seconds histogram
vllm:request_queue_time_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="0.8",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="1.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="15.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="30.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="60.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="120.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="240.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="480.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="960.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="1920.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="7680.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_queue_time_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 3.9806000131648034e-05
# HELP vllm:request_queue_time_seconds_created Histogram of time spent in WAITING phase for request.
# TYPE vllm:request_queue_time_seconds_created gauge
vllm:request_queue_time_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961802921e+09
# HELP vllm:request_inference_time_seconds Histogram of time spent in RUNNING phase for request.
# TYPE vllm:request_inference_time_seconds histogram
vllm:request_inference_time_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="0.8",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="1.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_inference_time_seconds_bucket{engine="0",le="15.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="30.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="60.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="120.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="240.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="480.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="960.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="1920.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="7680.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_inference_time_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 11.718473195000115
# HELP vllm:request_inference_time_seconds_created Histogram of time spent in RUNNING phase for request.
# TYPE vllm:request_inference_time_seconds_created gauge
vllm:request_inference_time_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961804109e+09
# HELP vllm:request_prefill_time_seconds Histogram of time spent in PREFILL phase for request.
# TYPE vllm:request_prefill_time_seconds histogram
vllm:request_prefill_time_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="0.8",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="1.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="15.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="30.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="60.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="120.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="240.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="480.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="960.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="1920.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="7680.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_time_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.04858271900229738
# HELP vllm:request_prefill_time_seconds_created Histogram of time spent in PREFILL phase for request.
# TYPE vllm:request_prefill_time_seconds_created gauge
vllm:request_prefill_time_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961805341e+09
# HELP vllm:request_decode_time_seconds Histogram of time spent in DECODE phase for request.
# TYPE vllm:request_decode_time_seconds histogram
vllm:request_decode_time_seconds_bucket{engine="0",le="0.3",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="0.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="0.8",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="1.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="2.5",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_decode_time_seconds_bucket{engine="0",le="15.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="30.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="40.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="60.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="120.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="240.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="480.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="960.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="1920.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="7680.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_decode_time_seconds_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 11.669890475997818
# HELP vllm:request_decode_time_seconds_created Histogram of time spent in DECODE phase for request.
# TYPE vllm:request_decode_time_seconds_created gauge
vllm:request_decode_time_seconds_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961806533e+09
# HELP vllm:request_prefill_kv_computed_tokens Histogram of new KV tokens computed during prefill (excluding cached tokens).
# TYPE vllm:request_prefill_kv_computed_tokens histogram
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prefill_kv_computed_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:request_prefill_kv_computed_tokens_created Histogram of new KV tokens computed during prefill (excluding cached tokens).
# TYPE vllm:request_prefill_kv_computed_tokens_created gauge
vllm:request_prefill_kv_computed_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961807995e+09
# HELP vllm:cache_config_info Information of the LLMEngine CacheConfig
# TYPE vllm:cache_config_info gauge
vllm:cache_config_info{block_size="16",cache_dtype="auto",calculate_kv_scales="False",cpu_kvcache_space_bytes="None",cpu_offload_gb="0.0",enable_prefix_caching="True",engine="0",gpu_memory_utilization="0.9",is_attention_free="False",kv_cache_memory_bytes="None",kv_offloading_backend="native",kv_offloading_size="None",kv_sharing_fast_prefill="False",mamba_block_size="None",mamba_cache_dtype="auto",mamba_cache_mode="none",mamba_page_size_padded="None",mamba_ssm_cache_dtype="auto",num_cpu_blocks="None",num_gpu_blocks="8258",num_gpu_blocks_override="None",prefix_caching_hash_algo="sha256",sliding_window="None",swap_space="4.0"} 1.0
# HELP http_requests_total Total number of requests by method, status and handler.
# TYPE http_requests_total counter
http_requests_total{handler="/v1/chat/completions",method="POST",status="2xx"} 1.0
# HELP http_requests_created Total number of requests by method, status and handler.
# TYPE http_requests_created gauge
http_requests_created{handler="/v1/chat/completions",method="POST",status="2xx"} 1.772224416592381e+09
# HELP http_request_size_bytes Content length of incoming requests by handler. Only value of header is respected. Otherwise ignored. No percentile calculated.
# TYPE http_request_size_bytes summary
http_request_size_bytes_count{handler="/v1/chat/completions"} 1.0
http_request_size_bytes_sum{handler="/v1/chat/completions"} 197.0
# HELP http_request_size_bytes_created Content length of incoming requests by handler. Only value of header is respected. Otherwise ignored. No percentile calculated.
# TYPE http_request_size_bytes_created gauge
http_request_size_bytes_created{handler="/v1/chat/completions"} 1.7722244165924487e+09
# HELP http_response_size_bytes Content length of outgoing responses by handler. Only value of header is respected. Otherwise ignored. No percentile calculated.
# TYPE http_response_size_bytes summary
http_response_size_bytes_count{handler="/v1/chat/completions"} 1.0
http_response_size_bytes_sum{handler="/v1/chat/completions"} 3028.0
# HELP http_response_size_bytes_created Content length of outgoing responses by handler. Only value of header is respected. Otherwise ignored. No percentile calculated.
# TYPE http_response_size_bytes_created gauge
http_response_size_bytes_created{handler="/v1/chat/completions"} 1.7722244165925236e+09
# HELP http_request_duration_highr_seconds Latency with many buckets but no API specific labels. Made for more accurate percentile calculations.
# TYPE http_request_duration_highr_seconds histogram
http_request_duration_highr_seconds_bucket{le="0.01"} 0.0
http_request_duration_highr_seconds_bucket{le="0.025"} 0.0
http_request_duration_highr_seconds_bucket{le="0.05"} 0.0
http_request_duration_highr_seconds_bucket{le="0.075"} 0.0
http_request_duration_highr_seconds_bucket{le="0.1"} 0.0
http_request_duration_highr_seconds_bucket{le="0.25"} 0.0
http_request_duration_highr_seconds_bucket{le="0.5"} 0.0
http_request_duration_highr_seconds_bucket{le="0.75"} 0.0
http_request_duration_highr_seconds_bucket{le="1.0"} 0.0
http_request_duration_highr_seconds_bucket{le="1.5"} 0.0
http_request_duration_highr_seconds_bucket{le="2.0"} 0.0
http_request_duration_highr_seconds_bucket{le="2.5"} 0.0
http_request_duration_highr_seconds_bucket{le="3.0"} 0.0
http_request_duration_highr_seconds_bucket{le="3.5"} 0.0
http_request_duration_highr_seconds_bucket{le="4.0"} 0.0
http_request_duration_highr_seconds_bucket{le="4.5"} 0.0
http_request_duration_highr_seconds_bucket{le="5.0"} 0.0
http_request_duration_highr_seconds_bucket{le="7.5"} 0.0
http_request_duration_highr_seconds_bucket{le="10.0"} 0.0
http_request_duration_highr_seconds_bucket{le="30.0"} 1.0
http_request_duration_highr_seconds_bucket{le="60.0"} 1.0
http_request_duration_highr_seconds_bucket{le="+Inf"} 1.0
http_request_duration_highr_seconds_count 1.0
http_request_duration_highr_seconds_sum 11.750964995000686
# HELP http_request_duration_highr_seconds_created Latency with many buckets but no API specific labels. Made for more accurate percentile calculations.
# TYPE http_request_duration_highr_seconds_created gauge
http_request_duration_highr_seconds_created 1.7722243963411007e+09
# HELP http_request_duration_seconds Latency with only few buckets by handler. Made to be only used if aggregation by handler is important.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{handler="/v1/chat/completions",le="0.1",method="POST"} 0.0
http_request_duration_seconds_bucket{handler="/v1/chat/completions",le="0.5",method="POST"} 0.0
http_request_duration_seconds_bucket{handler="/v1/chat/completions",le="1.0",method="POST"} 0.0
http_request_duration_seconds_bucket{handler="/v1/chat/completions",le="+Inf",method="POST"} 1.0
http_request_duration_seconds_count{handler="/v1/chat/completions",method="POST"} 1.0
http_request_duration_seconds_sum{handler="/v1/chat/completions",method="POST"} 11.750964995000686
# HELP http_request_duration_seconds_created Latency with only few buckets by handler. Made to be only used if aggregation by handler is important.
# TYPE http_request_duration_seconds_created gauge
http_request_duration_seconds_created{handler="/v1/chat/completions",method="POST"} 1.7722244165926113e+09
rteixeira@shockwave:~$
rteixeira@shockwave:~$
rteixeira@shockwave:~$ curl -s http://localhost:8002/metrics | egrep -i 'decode|prefill|throughput|tokens|latency|ttft|kv_cache|gpu_cache|scheduler' | head -n 80
# HELP vllm:kv_cache_usage_perc KV-cache usage. 1 means 100 percent usage.
# TYPE vllm:kv_cache_usage_perc gauge
vllm:kv_cache_usage_perc{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prefix_cache_queries_total Prefix cache queries, in terms of number of queried tokens.
# HELP vllm:prefix_cache_queries_created Prefix cache queries, in terms of number of queried tokens.
# HELP vllm:prefix_cache_hits_total Prefix cache hits, in terms of number of cached tokens.
# HELP vllm:prefix_cache_hits_created Prefix cache hits, in terms of number of cached tokens.
# HELP vllm:external_prefix_cache_queries_total External prefix cache queries from KV connector cross-instance cache sharing, in terms of number of queried tokens.
# HELP vllm:external_prefix_cache_queries_created External prefix cache queries from KV connector cross-instance cache sharing, in terms of number of queried tokens.
# HELP vllm:external_prefix_cache_hits_total External prefix cache hits from KV connector cross-instance cache sharing, in terms of number of cached tokens.
# HELP vllm:external_prefix_cache_hits_created External prefix cache hits from KV connector cross-instance cache sharing, in terms of number of cached tokens.
# HELP vllm:prompt_tokens_total Number of prefill tokens processed.
# TYPE vllm:prompt_tokens_total counter
vllm:prompt_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:prompt_tokens_created Number of prefill tokens processed.
# TYPE vllm:prompt_tokens_created gauge
vllm:prompt_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.772224396178228e+09
# HELP vllm:prompt_tokens_by_source_total Number of prompt tokens by source.
# TYPE vllm:prompt_tokens_by_source_total counter
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_compute"} 24.0
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_cache_hit"} 0.0
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="external_kv_transfer"} 0.0
# HELP vllm:prompt_tokens_by_source_created Number of prompt tokens by source.
# TYPE vllm:prompt_tokens_by_source_created gauge
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_compute"} 1.7722243961782753e+09
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_cache_hit"} 1.7722243961782959e+09
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="external_kv_transfer"} 1.7722243961783123e+09
# HELP vllm:prompt_tokens_cached_total Number of cached prompt tokens (local + external).
# TYPE vllm:prompt_tokens_cached_total counter
vllm:prompt_tokens_cached_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prompt_tokens_cached_created Number of cached prompt tokens (local + external).
# TYPE vllm:prompt_tokens_cached_created gauge
vllm:prompt_tokens_cached_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961783535e+09
# HELP vllm:prompt_tokens_recomputed_total Number of cached tokens recomputed for forward pass.
# TYPE vllm:prompt_tokens_recomputed_total counter
vllm:prompt_tokens_recomputed_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prompt_tokens_recomputed_created Number of cached tokens recomputed for forward pass.
# TYPE vllm:prompt_tokens_recomputed_created gauge
vllm:prompt_tokens_recomputed_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961783931e+09
# HELP vllm:generation_tokens_total Number of generation tokens processed.
# TYPE vllm:generation_tokens_total counter
vllm:generation_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:generation_tokens_created Number of generation tokens processed.
# TYPE vllm:generation_tokens_created gauge
vllm:generation_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961784277e+09
# HELP vllm:request_prompt_tokens Number of prefill tokens processed.
# TYPE vllm:request_prompt_tokens histogram
vllm:request_prompt_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:request_prompt_tokens_created Number of prefill tokens processed.
# TYPE vllm:request_prompt_tokens_created gauge
vllm:request_prompt_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961786902e+09
# HELP vllm:request_generation_tokens Number of generation tokens processed.
# TYPE vllm:request_generation_tokens histogram
vllm:request_generation_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
```




rteixeira@shockwave:~$ curl -s http://localhost:8002/metrics | egrep -i \
'decode|prefill|throughput|tokens|latency|ttft|kv_cache|gpu_cache|scheduler' | head -n 120
```
# HELP vllm:kv_cache_usage_perc KV-cache usage. 1 means 100 percent usage.
# TYPE vllm:kv_cache_usage_perc gauge
vllm:kv_cache_usage_perc{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prefix_cache_queries_total Prefix cache queries, in terms of number of queried tokens.
# HELP vllm:prefix_cache_queries_created Prefix cache queries, in terms of number of queried tokens.
# HELP vllm:prefix_cache_hits_total Prefix cache hits, in terms of number of cached tokens.
# HELP vllm:prefix_cache_hits_created Prefix cache hits, in terms of number of cached tokens.
# HELP vllm:external_prefix_cache_queries_total External prefix cache queries from KV connector cross-instance cache sharing, in terms of number of queried tokens.
# HELP vllm:external_prefix_cache_queries_created External prefix cache queries from KV connector cross-instance cache sharing, in terms of number of queried tokens.
# HELP vllm:external_prefix_cache_hits_total External prefix cache hits from KV connector cross-instance cache sharing, in terms of number of cached tokens.
# HELP vllm:external_prefix_cache_hits_created External prefix cache hits from KV connector cross-instance cache sharing, in terms of number of cached tokens.
# HELP vllm:prompt_tokens_total Number of prefill tokens processed.
# TYPE vllm:prompt_tokens_total counter
vllm:prompt_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:prompt_tokens_created Number of prefill tokens processed.
# TYPE vllm:prompt_tokens_created gauge
vllm:prompt_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.772224396178228e+09
# HELP vllm:prompt_tokens_by_source_total Number of prompt tokens by source.
# TYPE vllm:prompt_tokens_by_source_total counter
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_compute"} 24.0
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_cache_hit"} 0.0
vllm:prompt_tokens_by_source_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="external_kv_transfer"} 0.0
# HELP vllm:prompt_tokens_by_source_created Number of prompt tokens by source.
# TYPE vllm:prompt_tokens_by_source_created gauge
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_compute"} 1.7722243961782753e+09
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="local_cache_hit"} 1.7722243961782959e+09
vllm:prompt_tokens_by_source_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq",source="external_kv_transfer"} 1.7722243961783123e+09
# HELP vllm:prompt_tokens_cached_total Number of cached prompt tokens (local + external).
# TYPE vllm:prompt_tokens_cached_total counter
vllm:prompt_tokens_cached_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prompt_tokens_cached_created Number of cached prompt tokens (local + external).
# TYPE vllm:prompt_tokens_cached_created gauge
vllm:prompt_tokens_cached_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961783535e+09
# HELP vllm:prompt_tokens_recomputed_total Number of cached tokens recomputed for forward pass.
# TYPE vllm:prompt_tokens_recomputed_total counter
vllm:prompt_tokens_recomputed_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
# HELP vllm:prompt_tokens_recomputed_created Number of cached tokens recomputed for forward pass.
# TYPE vllm:prompt_tokens_recomputed_created gauge
vllm:prompt_tokens_recomputed_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961783931e+09
# HELP vllm:generation_tokens_total Number of generation tokens processed.
# TYPE vllm:generation_tokens_total counter
vllm:generation_tokens_total{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:generation_tokens_created Number of generation tokens processed.
# TYPE vllm:generation_tokens_created gauge
vllm:generation_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961784277e+09
# HELP vllm:request_prompt_tokens Number of prefill tokens processed.
# TYPE vllm:request_prompt_tokens histogram
vllm:request_prompt_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_prompt_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_prompt_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 24.0
# HELP vllm:request_prompt_tokens_created Number of prefill tokens processed.
# TYPE vllm:request_prompt_tokens_created gauge
vllm:request_prompt_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961786902e+09
# HELP vllm:request_generation_tokens Number of generation tokens processed.
# TYPE vllm:request_generation_tokens histogram
vllm:request_generation_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_generation_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_generation_tokens_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
# HELP vllm:request_generation_tokens_created Number of generation tokens processed.
# TYPE vllm:request_generation_tokens_created gauge
vllm:request_generation_tokens_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.772224396178866e+09
# HELP vllm:iteration_tokens_total Histogram of number of tokens per engine_step.
# TYPE vllm:iteration_tokens_total histogram
vllm:iteration_tokens_total_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:iteration_tokens_total_bucket{engine="0",le="8.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:iteration_tokens_total_bucket{engine="0",le="16.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 399.0
vllm:iteration_tokens_total_bucket{engine="0",le="32.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="64.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="128.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="256.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="512.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="1024.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="2048.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="4096.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="8192.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="16384.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_bucket{engine="0",le="+Inf",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_count{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 400.0
vllm:iteration_tokens_total_sum{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 424.0
# HELP vllm:iteration_tokens_total_created Histogram of number of tokens per engine_step.
# TYPE vllm:iteration_tokens_total_created gauge
vllm:iteration_tokens_total_created{engine="0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.7722243961789832e+09
# HELP vllm:request_max_num_generation_tokens Histogram of maximum number of requested generation tokens.
# TYPE vllm:request_max_num_generation_tokens histogram
vllm:request_max_num_generation_tokens_bucket{engine="0",le="1.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="2.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="5.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="10.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="20.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="50.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="100.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="200.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 0.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="500.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="1000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="2000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
vllm:request_max_num_generation_tokens_bucket{engine="0",le="5000.0",model_name="/mnt/shockwave/soundwave/models/llama3-70b-awq"} 1.0
```


